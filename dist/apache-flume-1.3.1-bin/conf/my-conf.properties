# Licensed to the Apache Software Foundation (ASF) under one
# or more contributor license agreements.  See the NOTICE file
# distributed with this work for additional information
# regarding copyright ownership.  The ASF licenses this file
# to you under the Apache License, Version 2.0 (the
# "License"); you may not use this file except in compliance
# with the License.  You may obtain a copy of the License at
#
#  http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing,
# software distributed under the License is distributed on an
# "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
# KIND, either express or implied.  See the License for the
# specific language governing permissions and limitations
# under the License.


# The configuration file needs to define the sources, 
# the channels and the sinks.
# Sources, channels and sinks are defined per agent, 
# in this case called 'agent'

#######################################################################################################################
### Remote Agent
#######################################################################################################################
remote_agent.sources = dirTailSource
remote_agent.channels = memoryChannel
remote_agent.sinks = avroSink

# Sources
# Tail Dir Source
remote_agent.sources.dirTailSource.type = com.realtimecep.flume.sources.DirTailEventDrivenSource
remote_agent.sources.dirTailSource.path = /var/log/httpd
remote_agent.sources.dirTailSource.filePrefix = access
remote_agent.sources.dirTailSource.scanPeriod = 3000
remote_agent.sources.dirTailSource.debugThroughput = false
remote_agent.sources.dirTailSource.interceptors = i1 i2
remote_agent.sources.dirTailSource.interceptors.i1.type = org.apache.flume.interceptor.TimestampInterceptor$Builder
remote_agent.sources.dirTailSource.interceptors.i2.type = org.apache.flume.interceptor.HostInterceptor$Builder
remote_agent.sources.dirTailSource.interceptors.i2.preserveExisting = false
remote_agent.sources.dirTailSource.interceptors.i2.hostHeader = hostname
remote_agent.sources.dirTailSource.selector.type = replicating
remote_agent.sources.dirTailSource.channels = memoryChannel

# Channels
remote_agent.channels.memoryChannel.type = memory
remote_agent.channels.memoryChannel.capacity = 1000
remote_agent.channels.memoryChannel.transactionCapacity = 100
remote_agent.channels.memoryChannel.keep-alive = 3

# Sinks
remote_agent.sinks.avroSink.type = avro
remote_agent.sinks.avroSink.channel = memoryChannel
remote_agent.sinks.avroSink.hostname = localhost
remote_agent.sinks.avroSink.port = 4545




#######################################################################################################################
### Collector
#######################################################################################################################
collector.sources = avroSource
collector.channels = memoryChannel1 memoryChannel2
collector.sinks = myHDFSSink CEPSink

# Sources
collector.sources.avroSource.type = avro
collector.sources.avroSource.channels = memoryChannel1 memoryChannel2
collector.sources.avroSource.bind = 0.0.0.0
collector.sources.avroSource.port = 4545

# Channels
collector.channels.memoryChannel1.type = memory
collector.channels.memoryChannel1.capacity = 1000
collector.channels.memoryChannel1.transactionCapacity = 100
collector.channels.memoryChannel1.keep-alive = 3

collector.channels.memoryChannel2.type = memory
collector.channels.memoryChannel2.capacity = 1000
collector.channels.memoryChannel2.transactionCapacity = 100
collector.channels.memoryChannel2.keep-alive = 3

# Sinks
collector.sinks.loggerSink.type = logger
collector.sinks.loggerSink.channel = memoryChannel1

collector.sinks.myHDFSSink.type = hdfs
collector.sinks.myHDFSSink.channel = memoryChannel2
collector.sinks.myHDFSSink.hdfs.path = hdfs://hadoop1:9000/data/%Y-%m-%d/%H
collector.sinks.myHDFSSink.hdfs.fileType = DataStream
collector.sinks.myHDFSSink.hdfs.writeFormat = Text
collector.sinks.myHDFSSink.hdfs.filePrefix = app
collector.sinks.myHDFSSink.hdfs.fileSuffix = .log
collector.sinks.myHDFSSink.hdfs.threadsPoolSize = 10
collector.sinks.myHDFSSink.hdfs.rollInterval = 60
collector.sinks.myHDFSSink.hdfs.rollSize = 125000
collector.sinks.myHDFSSink.hdfs.rollCount = 0
collector.sinks.myHDFSSink.hdfs.batchSize = 1000

collector.sinks.CEPSink.type = com.realtimecep.flume.sinks.CEPSink
collector.sinks.CEPSink.channel = memoryChannel1